{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"access_token\"]\n",
    "# login(token=os.environ[\"access_token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "local_id = os.path.join(\"/Users\", \"dina\", \"models\", \"models-tgi\", f\"{model_id}\")\n",
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=local_id, padding_side=\"left\"\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|eot_id|>'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=local_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompts = [\"hello how are you doing tell me?\", \"The Capital of India is\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000,  15339,   1268,    527,    499,   3815,   3371,    757,     30],\n",
       "        [128009, 128009, 128009, 128000,    791,  18880,    315,   6890,    374]],\n",
       "       device='mps:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1]], device='mps:0')}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenised = tokenizer(text=input_prompts, return_tensors=\"pt\", padding=True).to(\n",
    "    device=device\n",
    ")\n",
    "tokenised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000,  15339,   1268,    527,    499,   3815,   3371,    757,     30],\n",
       "        [128009, 128009, 128009, 128000,    791,  18880,    315,   6890,    374]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenised[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|>hello how are you doing tell me?',\n",
       " '<|eot_id|><|eot_id|><|eot_id|><|begin_of_text|>The Capital of India is']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(tokenised[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1]], device='mps:0')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenised[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Instruction Prompts and chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a smart AI assistant who speaks like a pirate.\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"where does the sun rises?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Aye Aye\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_token_text = tokenizer.apply_chat_template(\n",
    "#     conversation=prompt_template,\n",
    "#     add_generation_prompt=True,\n",
    "#     tokenize=False,\n",
    "#     # tokenize=True,\n",
    "#     padding=True,\n",
    "#     return_tensors=\"pt\",\n",
    "# )\n",
    "\n",
    "# prompt_token_text\n",
    "# tokenised = tokenizer(text=prompt_token_text, padding=True, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised = tokenizer.apply_chat_template(\n",
    "    conversation=prompt_template,\n",
    "    # add_generation_prompt=True,\n",
    "    add_generation_prompt=False,\n",
    "    continue_final_message=True,\n",
    "    # tokenize=False,\n",
    "    tokenize=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,   2696,\n",
      "             25,   6790,    220,   2366,     18,    198,  15724,   2696,     25,\n",
      "            220,    975,  13806,    220,   2366,     20,    271,   2675,    527,\n",
      "            264,   7941,  15592,  18328,    889,  21881,   1093,    264,  55066,\n",
      "             13, 128009, 128006,    882, 128007,    271,   2940,   1587,    279,\n",
      "           7160,  38268,     30, 128009, 128006,  78191, 128007,    271,     32,\n",
      "           9188,    362,   9188]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(tokenised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Feb 2025\\n\\nYou are a smart AI assistant who speaks like a pirate.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nwhere does the sun rises?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nAye Aye']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(tokenised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "out = model.generate(tokenised, max_new_tokens=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 14 Feb 2025\n",
      "\n",
      "You are a smart AI assistant who speaks like a pirate.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "where does the sun rises?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Aye Aye Captain, ye be askin' about the sun risin' place, eh? Well, mate\n"
     ]
    }
   ],
   "source": [
    "out_decoded = tokenizer.batch_decode(out)\n",
    "print(out_decoded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello how are\"\n",
    "tok = tokenizer([text], return_tensors=\"pt\")\n",
    "tok_ids = tok[\"input_ids\"].to(device)\n",
    "\n",
    "out = model(tok_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.8438,  3.5625,  7.0000,  ..., -1.2500, -1.2500, -1.2500],\n",
       "         [19.0000,  3.8438,  3.6875,  ..., -1.0781, -1.0781, -1.0781],\n",
       "         [ 9.3750,  5.8750,  3.9375,  ..., -0.2148, -0.2148, -0.2158],\n",
       "         [ 9.8750,  6.3125,  1.7266,  ...,  0.4023,  0.4023,  0.4004]]],\n",
       "       device='mps:0', dtype=torch.bfloat16, grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 128256])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.logits.shape\n",
    "# here 1 -> batch size\n",
    "# 4 -> number of tokens\n",
    "# 128256 -> vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' you'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(out.logits[:, -1].argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tags, are you']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(out.logits.argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16309"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.logits[:, 0].argmax(axis=-1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tags'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(16309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dina/Work/llmfinetune/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "p_dist = nn.Softmax()(out.logits[0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9514\n",
      "499\n",
      "1472\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab[\"you\"])\n",
    "print(tokenizer.vocab[\"Ġyou\"])\n",
    "print(tokenizer.vocab[\"ĠYou\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1723e-06, device='mps:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dist[449]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.0545e-05, device='mps:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dist[1472]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(499, device='mps:0')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dist.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[128000,  29673,    311,    856,  28277,   5613]])\n",
      "['<|begin_of_text|>Subscribe to my youtube channel']\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"Subscribe to my youtube channel\"]\n",
    "tokenized = tokenizer(sentence, return_tensors=\"pt\")[\"input_ids\"]\n",
    "print(tokenized)\n",
    "print(tokenizer.batch_decode(tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[128000,  29673,    311,    856,  28277]])\n",
      "tensor([[29673,   311,   856, 28277,  5613]])\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenized[:, :-1]  # (start) to (end-1)\n",
    "target_ids = tokenized[:, 1:]  # (start+1) to (end)\n",
    "print(input_ids)\n",
    "print(target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
